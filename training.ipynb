{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from logging import getLogger\n",
    "import recbole\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.model.sequential_recommender import GRU4Rec\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger, get_model, get_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict = {\n",
    "    # seq_separator: \",\"\n",
    "    'data_path':'',\n",
    "    'USER_ID_FIELD': 'user_id',\n",
    "    'ITEM_ID_FIELD': 'item_id',\n",
    "    'RATING_FIELD': 'rating',\n",
    "\n",
    "    'load_col': {'inter': ['user_id', 'item_id', 'rating']},\n",
    "    'device' : 'GPU',\n",
    "\n",
    "    # model config\n",
    "    'embedding_size': '64',\n",
    "    'hidden_size': '128',\n",
    "    'num_layers': '1',\n",
    "    'dropout_prob': '0.3',\n",
    "    'loss_type': 'CE',\n",
    "    'threshold':{'rating': 0},\n",
    "    \n",
    "\n",
    "    # 'eval_setting': TO_LS, full,\n",
    "    'train_neg_sample_args': None,\n",
    "    'group_by_user': True,\n",
    "    'metrics': [\"Recall\", \"MRR\", \"NDCG\", \"Hit\", \"Precision\"],\n",
    "    'topk': 10,\n",
    "    'metric_decimal_place': 5,\n",
    "\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 20,\n",
    "    'train_batch_size': '512',\n",
    "    'eval_batch_size': '512',\n",
    "    'valid_metric': 'MRR@10',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21 Jun 15:18    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = joke\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 20\n",
      "train_batch_size = 512\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': None, 'mode': {'valid': 'labeled', 'test': 'labeled'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 512\n",
      "metric_decimal_place = 5\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = {'rating': 0}\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'rating']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "mlp_hidden_size = [64, 64, 64]\n",
      "dropout_prob = 0.3\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.CONTEXT\n",
      "device = cpu\n",
      "hidden_size = 128\n",
      "num_layers = 1\n",
      "loss_type = CE\n",
      "group_by_user = True\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "valid_neg_sample_args = {'distribution': 'none', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'none', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "\n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = joke\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 20\n",
      "train_batch_size = 512\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': None, 'mode': {'valid': 'labeled', 'test': 'labeled'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 512\n",
      "metric_decimal_place = 5\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = {'rating': 0}\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'rating']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "mlp_hidden_size = [64, 64, 64]\n",
      "dropout_prob = 0.3\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.CONTEXT\n",
      "device = cpu\n",
      "hidden_size = 128\n",
      "num_layers = 1\n",
      "loss_type = CE\n",
      "group_by_user = True\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "valid_neg_sample_args = {'distribution': 'none', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'none', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "\n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = joke\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 20\n",
      "train_batch_size = 512\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': None, 'mode': {'valid': 'labeled', 'test': 'labeled'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 512\n",
      "metric_decimal_place = 5\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = {'rating': 0}\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'rating']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "mlp_hidden_size = [64, 64, 64]\n",
      "dropout_prob = 0.3\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.CONTEXT\n",
      "device = cpu\n",
      "hidden_size = 128\n",
      "num_layers = 1\n",
      "loss_type = CE\n",
      "group_by_user = True\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "valid_neg_sample_args = {'distribution': 'none', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'none', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "\n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = joke\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 20\n",
      "train_batch_size = 512\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': None, 'mode': {'valid': 'labeled', 'test': 'labeled'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 512\n",
      "metric_decimal_place = 5\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = {'rating': 0}\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'rating']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "mlp_hidden_size = [64, 64, 64]\n",
      "dropout_prob = 0.3\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.CONTEXT\n",
      "device = cpu\n",
      "hidden_size = 128\n",
      "num_layers = 1\n",
      "loss_type = CE\n",
      "group_by_user = True\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "valid_neg_sample_args = {'distribution': 'none', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'none', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "\n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = joke\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = False\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 20\n",
      "train_batch_size = 512\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': None, 'mode': {'valid': 'labeled', 'test': 'labeled'}}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 512\n",
      "metric_decimal_place = 5\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = {'rating': 0}\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id', 'rating']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = recbole\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "embedding_size = 64\n",
      "mlp_hidden_size = [64, 64, 64]\n",
      "dropout_prob = 0.3\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.CONTEXT\n",
      "device = cpu\n",
      "hidden_size = 128\n",
      "num_layers = 1\n",
      "loss_type = CE\n",
      "group_by_user = True\n",
      "MODEL_INPUT_TYPE = InputType.POINTWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "valid_neg_sample_args = {'distribution': 'none', 'sample_num': 'none'}\n",
      "test_neg_sample_args = {'distribution': 'none', 'sample_num': 'none'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = Config(model='NFM', dataset='joke', config_dict = parameter_dict)\n",
    "\n",
    "init_seed(config['seed'], config['reproducibility'])\n",
    "\n",
    "# logger initialization\n",
    "init_logger(config)\n",
    "logger = getLogger()\n",
    "# Create handlers\n",
    "c_handler = logging.StreamHandler()\n",
    "c_handler.setLevel(logging.INFO)\n",
    "logger.addHandler(c_handler)\n",
    "\n",
    "# write config info into log\n",
    "logger.info(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\After\\Fuse AI Trainee\\fuse_env\\Lib\\site-packages\\recbole\\data\\dataset\\dataset.py:648: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=0, inplace=True)\n",
      "d:\\After\\Fuse AI Trainee\\fuse_env\\Lib\\site-packages\\recbole\\data\\dataset\\dataset.py:650: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  feat[field].fillna(value=feat[field].mean(), inplace=True)\n",
      "21 Jun 15:18    INFO  joke\n",
      "The number of users: 237\n",
      "Average actions of users: 42.3728813559322\n",
      "The number of items: 141\n",
      "Average actions of items: 71.42857142857143\n",
      "The number of inters: 10000\n",
      "The sparsity of the dataset: 70.07511147020978%\n",
      "Remain Fields: ['user_id', 'item_id', 'label']\n",
      "joke\n",
      "The number of users: 237\n",
      "Average actions of users: 42.3728813559322\n",
      "The number of items: 141\n",
      "Average actions of items: 71.42857142857143\n",
      "The number of inters: 10000\n",
      "The sparsity of the dataset: 70.07511147020978%\n",
      "Remain Fields: ['user_id', 'item_id', 'label']\n",
      "joke\n",
      "The number of users: 237\n",
      "Average actions of users: 42.3728813559322\n",
      "The number of items: 141\n",
      "Average actions of items: 71.42857142857143\n",
      "The number of inters: 10000\n",
      "The sparsity of the dataset: 70.07511147020978%\n",
      "Remain Fields: ['user_id', 'item_id', 'label']\n",
      "joke\n",
      "The number of users: 237\n",
      "Average actions of users: 42.3728813559322\n",
      "The number of items: 141\n",
      "Average actions of items: 71.42857142857143\n",
      "The number of inters: 10000\n",
      "The sparsity of the dataset: 70.07511147020978%\n",
      "Remain Fields: ['user_id', 'item_id', 'label']\n",
      "joke\n",
      "The number of users: 237\n",
      "Average actions of users: 42.3728813559322\n",
      "The number of items: 141\n",
      "Average actions of items: 71.42857142857143\n",
      "The number of inters: 10000\n",
      "The sparsity of the dataset: 70.07511147020978%\n",
      "Remain Fields: ['user_id', 'item_id', 'label']\n"
     ]
    }
   ],
   "source": [
    "dataset = create_dataset(config)\n",
    "logger.info(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21 Jun 15:18    INFO  [Training]: train_batch_size = [512] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "[Training]: train_batch_size = [512] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "[Training]: train_batch_size = [512] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "[Training]: train_batch_size = [512] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "[Training]: train_batch_size = [512] train_neg_sample_args: [{'distribution': 'none', 'sample_num': 'none', 'alpha': 'none', 'dynamic': False, 'candidate_num': 0}]\n",
      "21 Jun 15:18    INFO  [Evaluation]: eval_batch_size = [512] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': None, 'mode': {'valid': 'labeled', 'test': 'labeled'}}]\n",
      "[Evaluation]: eval_batch_size = [512] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': None, 'mode': {'valid': 'labeled', 'test': 'labeled'}}]\n",
      "[Evaluation]: eval_batch_size = [512] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': None, 'mode': {'valid': 'labeled', 'test': 'labeled'}}]\n",
      "[Evaluation]: eval_batch_size = [512] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': None, 'mode': {'valid': 'labeled', 'test': 'labeled'}}]\n",
      "[Evaluation]: eval_batch_size = [512] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'order': 'RO', 'group_by': None, 'mode': {'valid': 'labeled', 'test': 'labeled'}}]\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, test_data = data_preparation(config, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The batch_size of interaction: 512\n",
      "    user_id, torch.Size([512]), cpu, torch.int64\n",
      "    item_id, torch.Size([512]), cpu, torch.int64\n",
      "    label, torch.Size([512]), cpu, torch.float32\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in train_data:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(recbole.model.context_aware_recommender.nfm.NFM, device(type='cpu'))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfm_model = get_model(config[\"model\"])\n",
    "nfm_model, config[\"device\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21 Jun 15:18    INFO  NFM(\n",
      "  (token_embedding_table): FMEmbedding(\n",
      "    (embedding): Embedding(378, 64)\n",
      "  )\n",
      "  (first_order_linear): FMFirstOrderLinear(\n",
      "    (token_embedding_table): FMEmbedding(\n",
      "      (embedding): Embedding(378, 1)\n",
      "    )\n",
      "  )\n",
      "  (fm): BaseFactorizationMachine()\n",
      "  (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (mlp_layers): MLPLayers(\n",
      "    (mlp_layers): Sequential(\n",
      "      (0): Dropout(p=0.3, inplace=False)\n",
      "      (1): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Sigmoid()\n",
      "      (4): Dropout(p=0.3, inplace=False)\n",
      "      (5): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): Sigmoid()\n",
      "      (8): Dropout(p=0.3, inplace=False)\n",
      "      (9): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (10): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (11): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (predict_layer): Linear(in_features=64, out_features=1, bias=False)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (loss): BCEWithLogitsLoss()\n",
      ")\n",
      "Trainable parameters: 37627\n",
      "NFM(\n",
      "  (token_embedding_table): FMEmbedding(\n",
      "    (embedding): Embedding(378, 64)\n",
      "  )\n",
      "  (first_order_linear): FMFirstOrderLinear(\n",
      "    (token_embedding_table): FMEmbedding(\n",
      "      (embedding): Embedding(378, 1)\n",
      "    )\n",
      "  )\n",
      "  (fm): BaseFactorizationMachine()\n",
      "  (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (mlp_layers): MLPLayers(\n",
      "    (mlp_layers): Sequential(\n",
      "      (0): Dropout(p=0.3, inplace=False)\n",
      "      (1): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Sigmoid()\n",
      "      (4): Dropout(p=0.3, inplace=False)\n",
      "      (5): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): Sigmoid()\n",
      "      (8): Dropout(p=0.3, inplace=False)\n",
      "      (9): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (10): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (11): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (predict_layer): Linear(in_features=64, out_features=1, bias=False)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (loss): BCEWithLogitsLoss()\n",
      ")\n",
      "Trainable parameters: 37627\n",
      "NFM(\n",
      "  (token_embedding_table): FMEmbedding(\n",
      "    (embedding): Embedding(378, 64)\n",
      "  )\n",
      "  (first_order_linear): FMFirstOrderLinear(\n",
      "    (token_embedding_table): FMEmbedding(\n",
      "      (embedding): Embedding(378, 1)\n",
      "    )\n",
      "  )\n",
      "  (fm): BaseFactorizationMachine()\n",
      "  (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (mlp_layers): MLPLayers(\n",
      "    (mlp_layers): Sequential(\n",
      "      (0): Dropout(p=0.3, inplace=False)\n",
      "      (1): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Sigmoid()\n",
      "      (4): Dropout(p=0.3, inplace=False)\n",
      "      (5): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): Sigmoid()\n",
      "      (8): Dropout(p=0.3, inplace=False)\n",
      "      (9): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (10): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (11): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (predict_layer): Linear(in_features=64, out_features=1, bias=False)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (loss): BCEWithLogitsLoss()\n",
      ")\n",
      "Trainable parameters: 37627\n",
      "NFM(\n",
      "  (token_embedding_table): FMEmbedding(\n",
      "    (embedding): Embedding(378, 64)\n",
      "  )\n",
      "  (first_order_linear): FMFirstOrderLinear(\n",
      "    (token_embedding_table): FMEmbedding(\n",
      "      (embedding): Embedding(378, 1)\n",
      "    )\n",
      "  )\n",
      "  (fm): BaseFactorizationMachine()\n",
      "  (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (mlp_layers): MLPLayers(\n",
      "    (mlp_layers): Sequential(\n",
      "      (0): Dropout(p=0.3, inplace=False)\n",
      "      (1): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Sigmoid()\n",
      "      (4): Dropout(p=0.3, inplace=False)\n",
      "      (5): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): Sigmoid()\n",
      "      (8): Dropout(p=0.3, inplace=False)\n",
      "      (9): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (10): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (11): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (predict_layer): Linear(in_features=64, out_features=1, bias=False)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (loss): BCEWithLogitsLoss()\n",
      ")\n",
      "Trainable parameters: 37627\n",
      "NFM(\n",
      "  (token_embedding_table): FMEmbedding(\n",
      "    (embedding): Embedding(378, 64)\n",
      "  )\n",
      "  (first_order_linear): FMFirstOrderLinear(\n",
      "    (token_embedding_table): FMEmbedding(\n",
      "      (embedding): Embedding(378, 1)\n",
      "    )\n",
      "  )\n",
      "  (fm): BaseFactorizationMachine()\n",
      "  (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (mlp_layers): MLPLayers(\n",
      "    (mlp_layers): Sequential(\n",
      "      (0): Dropout(p=0.3, inplace=False)\n",
      "      (1): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Sigmoid()\n",
      "      (4): Dropout(p=0.3, inplace=False)\n",
      "      (5): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): Sigmoid()\n",
      "      (8): Dropout(p=0.3, inplace=False)\n",
      "      (9): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (10): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (11): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (predict_layer): Linear(in_features=64, out_features=1, bias=False)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (loss): BCEWithLogitsLoss()\n",
      ")\n",
      "Trainable parameters: 37627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NFM(\n",
      "  (token_embedding_table): FMEmbedding(\n",
      "    (embedding): Embedding(378, 64)\n",
      "  )\n",
      "  (first_order_linear): FMFirstOrderLinear(\n",
      "    (token_embedding_table): FMEmbedding(\n",
      "      (embedding): Embedding(378, 1)\n",
      "    )\n",
      "  )\n",
      "  (fm): BaseFactorizationMachine()\n",
      "  (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (mlp_layers): MLPLayers(\n",
      "    (mlp_layers): Sequential(\n",
      "      (0): Dropout(p=0.3, inplace=False)\n",
      "      (1): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Sigmoid()\n",
      "      (4): Dropout(p=0.3, inplace=False)\n",
      "      (5): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): Sigmoid()\n",
      "      (8): Dropout(p=0.3, inplace=False)\n",
      "      (9): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (10): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (11): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (predict_layer): Linear(in_features=64, out_features=1, bias=False)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (loss): BCEWithLogitsLoss()\n",
      ")\n",
      "Trainable parameters: 37627\n"
     ]
    }
   ],
   "source": [
    "model = nfm_model(config, train_data.dataset).to(config['device'])\n",
    "logger.info(model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('NFM', <ModelType.CONTEXT: 3>, device(type='cpu'))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config[\"model\"], config[\"MODEL_TYPE\"], config[\"device\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<recbole.trainer.trainer.Trainer at 0x10f0c6867d0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  trainer loading and initialization\n",
    "trainer = Trainer(config, model)\n",
    "trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21 Jun 15:19    INFO  epoch 0 training [time: 1.02s, train loss: 10.4746]\n",
      "epoch 0 training [time: 1.02s, train loss: 10.4746]\n",
      "epoch 0 training [time: 1.02s, train loss: 10.4746]\n",
      "epoch 0 training [time: 1.02s, train loss: 10.4746]\n",
      "epoch 0 training [time: 1.02s, train loss: 10.4746]\n",
      "21 Jun 15:19    INFO  Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "21 Jun 15:19    INFO  epoch 1 training [time: 1.03s, train loss: 10.4021]\n",
      "epoch 1 training [time: 1.03s, train loss: 10.4021]\n",
      "epoch 1 training [time: 1.03s, train loss: 10.4021]\n",
      "epoch 1 training [time: 1.03s, train loss: 10.4021]\n",
      "epoch 1 training [time: 1.03s, train loss: 10.4021]\n",
      "21 Jun 15:19    INFO  Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "21 Jun 15:19    INFO  epoch 2 training [time: 0.91s, train loss: 10.2996]\n",
      "epoch 2 training [time: 0.91s, train loss: 10.2996]\n",
      "epoch 2 training [time: 0.91s, train loss: 10.2996]\n",
      "epoch 2 training [time: 0.91s, train loss: 10.2996]\n",
      "epoch 2 training [time: 0.91s, train loss: 10.2996]\n",
      "21 Jun 15:19    INFO  Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "21 Jun 15:19    INFO  epoch 3 training [time: 0.87s, train loss: 10.2371]\n",
      "epoch 3 training [time: 0.87s, train loss: 10.2371]\n",
      "epoch 3 training [time: 0.87s, train loss: 10.2371]\n",
      "epoch 3 training [time: 0.87s, train loss: 10.2371]\n",
      "epoch 3 training [time: 0.87s, train loss: 10.2371]\n",
      "21 Jun 15:19    INFO  Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "21 Jun 15:19    INFO  epoch 4 training [time: 0.99s, train loss: 10.1418]\n",
      "epoch 4 training [time: 0.99s, train loss: 10.1418]\n",
      "epoch 4 training [time: 0.99s, train loss: 10.1418]\n",
      "epoch 4 training [time: 0.99s, train loss: 10.1418]\n",
      "epoch 4 training [time: 0.99s, train loss: 10.1418]\n",
      "21 Jun 15:19    INFO  Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "21 Jun 15:19    INFO  epoch 5 training [time: 0.87s, train loss: 9.9368]\n",
      "epoch 5 training [time: 0.87s, train loss: 9.9368]\n",
      "epoch 5 training [time: 0.87s, train loss: 9.9368]\n",
      "epoch 5 training [time: 0.87s, train loss: 9.9368]\n",
      "epoch 5 training [time: 0.87s, train loss: 9.9368]\n",
      "21 Jun 15:19    INFO  Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "21 Jun 15:19    INFO  epoch 6 training [time: 0.90s, train loss: 9.5557]\n",
      "epoch 6 training [time: 0.90s, train loss: 9.5557]\n",
      "epoch 6 training [time: 0.90s, train loss: 9.5557]\n",
      "epoch 6 training [time: 0.90s, train loss: 9.5557]\n",
      "epoch 6 training [time: 0.90s, train loss: 9.5557]\n",
      "21 Jun 15:19    INFO  Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "21 Jun 15:19    INFO  epoch 7 training [time: 0.89s, train loss: 8.8817]\n",
      "epoch 7 training [time: 0.89s, train loss: 8.8817]\n",
      "epoch 7 training [time: 0.89s, train loss: 8.8817]\n",
      "epoch 7 training [time: 0.89s, train loss: 8.8817]\n",
      "epoch 7 training [time: 0.89s, train loss: 8.8817]\n",
      "21 Jun 15:19    INFO  Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "21 Jun 15:19    INFO  epoch 8 training [time: 0.96s, train loss: 7.9361]\n",
      "epoch 8 training [time: 0.96s, train loss: 7.9361]\n",
      "epoch 8 training [time: 0.96s, train loss: 7.9361]\n",
      "epoch 8 training [time: 0.96s, train loss: 7.9361]\n",
      "epoch 8 training [time: 0.96s, train loss: 7.9361]\n",
      "21 Jun 15:19    INFO  Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "21 Jun 15:19    INFO  epoch 9 training [time: 0.81s, train loss: 7.0636]\n",
      "epoch 9 training [time: 0.81s, train loss: 7.0636]\n",
      "epoch 9 training [time: 0.81s, train loss: 7.0636]\n",
      "epoch 9 training [time: 0.81s, train loss: 7.0636]\n",
      "epoch 9 training [time: 0.81s, train loss: 7.0636]\n",
      "21 Jun 15:19    INFO  Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "21 Jun 15:19    INFO  epoch 10 training [time: 0.83s, train loss: 6.1522]\n",
      "epoch 10 training [time: 0.83s, train loss: 6.1522]\n",
      "epoch 10 training [time: 0.83s, train loss: 6.1522]\n",
      "epoch 10 training [time: 0.83s, train loss: 6.1522]\n",
      "epoch 10 training [time: 0.83s, train loss: 6.1522]\n",
      "21 Jun 15:19    INFO  Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "21 Jun 15:19    INFO  epoch 11 training [time: 0.81s, train loss: 5.4432]\n",
      "epoch 11 training [time: 0.81s, train loss: 5.4432]\n",
      "epoch 11 training [time: 0.81s, train loss: 5.4432]\n",
      "epoch 11 training [time: 0.81s, train loss: 5.4432]\n",
      "epoch 11 training [time: 0.81s, train loss: 5.4432]\n",
      "21 Jun 15:19    INFO  Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "21 Jun 15:19    INFO  epoch 12 training [time: 0.85s, train loss: 4.8043]\n",
      "epoch 12 training [time: 0.85s, train loss: 4.8043]\n",
      "epoch 12 training [time: 0.85s, train loss: 4.8043]\n",
      "epoch 12 training [time: 0.85s, train loss: 4.8043]\n",
      "epoch 12 training [time: 0.85s, train loss: 4.8043]\n",
      "21 Jun 15:19    INFO  Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "21 Jun 15:19    INFO  epoch 13 training [time: 0.83s, train loss: 4.3241]\n",
      "epoch 13 training [time: 0.83s, train loss: 4.3241]\n",
      "epoch 13 training [time: 0.83s, train loss: 4.3241]\n",
      "epoch 13 training [time: 0.83s, train loss: 4.3241]\n",
      "epoch 13 training [time: 0.83s, train loss: 4.3241]\n",
      "21 Jun 15:19    INFO  Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "21 Jun 15:19    INFO  epoch 14 training [time: 0.86s, train loss: 3.8810]\n",
      "epoch 14 training [time: 0.86s, train loss: 3.8810]\n",
      "epoch 14 training [time: 0.86s, train loss: 3.8810]\n",
      "epoch 14 training [time: 0.86s, train loss: 3.8810]\n",
      "epoch 14 training [time: 0.86s, train loss: 3.8810]\n",
      "21 Jun 15:19    INFO  Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "21 Jun 15:19    INFO  epoch 15 training [time: 0.98s, train loss: 3.6071]\n",
      "epoch 15 training [time: 0.98s, train loss: 3.6071]\n",
      "epoch 15 training [time: 0.98s, train loss: 3.6071]\n",
      "epoch 15 training [time: 0.98s, train loss: 3.6071]\n",
      "epoch 15 training [time: 0.98s, train loss: 3.6071]\n",
      "21 Jun 15:19    INFO  Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "21 Jun 15:19    INFO  epoch 16 training [time: 0.99s, train loss: 3.0505]\n",
      "epoch 16 training [time: 0.99s, train loss: 3.0505]\n",
      "epoch 16 training [time: 0.99s, train loss: 3.0505]\n",
      "epoch 16 training [time: 0.99s, train loss: 3.0505]\n",
      "epoch 16 training [time: 0.99s, train loss: 3.0505]\n",
      "21 Jun 15:19    INFO  Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "21 Jun 15:19    INFO  epoch 17 training [time: 0.82s, train loss: 2.8673]\n",
      "epoch 17 training [time: 0.82s, train loss: 2.8673]\n",
      "epoch 17 training [time: 0.82s, train loss: 2.8673]\n",
      "epoch 17 training [time: 0.82s, train loss: 2.8673]\n",
      "epoch 17 training [time: 0.82s, train loss: 2.8673]\n",
      "21 Jun 15:19    INFO  Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "21 Jun 15:19    INFO  epoch 18 training [time: 0.87s, train loss: 2.7893]\n",
      "epoch 18 training [time: 0.87s, train loss: 2.7893]\n",
      "epoch 18 training [time: 0.87s, train loss: 2.7893]\n",
      "epoch 18 training [time: 0.87s, train loss: 2.7893]\n",
      "epoch 18 training [time: 0.87s, train loss: 2.7893]\n",
      "21 Jun 15:19    INFO  Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "21 Jun 15:19    INFO  epoch 19 training [time: 0.81s, train loss: 2.5709]\n",
      "epoch 19 training [time: 0.81s, train loss: 2.5709]\n",
      "epoch 19 training [time: 0.81s, train loss: 2.5709]\n",
      "epoch 19 training [time: 0.81s, train loss: 2.5709]\n",
      "epoch 19 training [time: 0.81s, train loss: 2.5709]\n",
      "21 Jun 15:19    INFO  Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n",
      "Saving current: saved\\NFM-Jun-21-2024_15-18-19.pth\n"
     ]
    }
   ],
   "source": [
    "# model training\n",
    "best_valid_score, best_valid_result = trainer.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\logging\\__init__.py:1113\u001b[0m, in \u001b[0;36mStreamHandler.emit\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m   1112\u001b[0m \u001b[38;5;66;03m# issue 35046: merged two stream.writes into one.\u001b[39;00m\n\u001b[1;32m-> 1113\u001b[0m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mterminator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[1;32md:\\After\\Fuse AI Trainee\\fuse_env\\Lib\\site-packages\\colorama\\ansitowin32.py:41\u001b[0m, in \u001b[0;36mStreamWrapper.write\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__convertor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\After\\Fuse AI Trainee\\fuse_env\\Lib\\site-packages\\colorama\\ansitowin32.py:162\u001b[0m, in \u001b[0;36mAnsiToWin32.write\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrip \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert:\n\u001b[1;32m--> 162\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_and_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\After\\Fuse AI Trainee\\fuse_env\\Lib\\site-packages\\colorama\\ansitowin32.py:187\u001b[0m, in \u001b[0;36mAnsiToWin32.write_and_convert\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    186\u001b[0m start, end \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mspan()\n\u001b[1;32m--> 187\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_plain_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_ansi(\u001b[38;5;241m*\u001b[39mmatch\u001b[38;5;241m.\u001b[39mgroups())\n",
      "File \u001b[1;32md:\\After\\Fuse AI Trainee\\fuse_env\\Lib\\site-packages\\colorama\\ansitowin32.py:195\u001b[0m, in \u001b[0;36mAnsiToWin32.write_plain_text\u001b[1;34m(self, text, start, end)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;241m<\u001b[39m end:\n\u001b[1;32m--> 195\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapped\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[1;32md:\\After\\Fuse AI Trainee\\fuse_env\\Lib\\site-packages\\ipykernel\\iostream.py:679\u001b[0m, in \u001b[0;36mOutStream.write\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    678\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI/O operation on closed file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 679\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    681\u001b[0m is_child \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_master_process()\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrecbole\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquick_start\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_data_and_model\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load the trained model and data\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m config, model, dataset, train_data, valid_data, test_data \u001b[38;5;241m=\u001b[39m \u001b[43mload_data_and_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaved\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mNFM-Jun-21-2024_15-18-19.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\After\\Fuse AI Trainee\\fuse_env\\Lib\\site-packages\\recbole\\quick_start\\quick_start.py:255\u001b[0m, in \u001b[0;36mload_data_and_model\u001b[1;34m(model_file)\u001b[0m\n\u001b[0;32m    253\u001b[0m init_logger(config)\n\u001b[0;32m    254\u001b[0m logger \u001b[38;5;241m=\u001b[39m getLogger()\n\u001b[1;32m--> 255\u001b[0m \u001b[43mlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    257\u001b[0m dataset \u001b[38;5;241m=\u001b[39m create_dataset(config)\n\u001b[0;32m    258\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(dataset)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\logging\\__init__.py:1489\u001b[0m, in \u001b[0;36mLogger.info\u001b[1;34m(self, msg, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1480\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1481\u001b[0m \u001b[38;5;124;03mLog 'msg % args' with severity 'INFO'.\u001b[39;00m\n\u001b[0;32m   1482\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;124;03mlogger.info(\"Houston, we have a %s\", \"interesting problem\", exc_info=1)\u001b[39;00m\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misEnabledFor(INFO):\n\u001b[1;32m-> 1489\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINFO\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\logging\\__init__.py:1634\u001b[0m, in \u001b[0;36mLogger._log\u001b[1;34m(self, level, msg, args, exc_info, extra, stack_info, stacklevel)\u001b[0m\n\u001b[0;32m   1631\u001b[0m         exc_info \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n\u001b[0;32m   1632\u001b[0m record \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakeRecord(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, level, fn, lno, msg, args,\n\u001b[0;32m   1633\u001b[0m                          exc_info, func, extra, sinfo)\n\u001b[1;32m-> 1634\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\logging\\__init__.py:1644\u001b[0m, in \u001b[0;36mLogger.handle\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m   1637\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1638\u001b[0m \u001b[38;5;124;03mCall the handlers for the specified record.\u001b[39;00m\n\u001b[0;32m   1639\u001b[0m \n\u001b[0;32m   1640\u001b[0m \u001b[38;5;124;03mThis method is used for unpickled records received from a socket, as\u001b[39;00m\n\u001b[0;32m   1641\u001b[0m \u001b[38;5;124;03mwell as those created locally. Logger-level filtering is applied.\u001b[39;00m\n\u001b[0;32m   1642\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisabled) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter(record):\n\u001b[1;32m-> 1644\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallHandlers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\logging\\__init__.py:1706\u001b[0m, in \u001b[0;36mLogger.callHandlers\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m   1704\u001b[0m     found \u001b[38;5;241m=\u001b[39m found \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1705\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m record\u001b[38;5;241m.\u001b[39mlevelno \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m hdlr\u001b[38;5;241m.\u001b[39mlevel:\n\u001b[1;32m-> 1706\u001b[0m         \u001b[43mhdlr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m c\u001b[38;5;241m.\u001b[39mpropagate:\n\u001b[0;32m   1708\u001b[0m     c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m    \u001b[38;5;66;03m#break out\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\logging\\__init__.py:978\u001b[0m, in \u001b[0;36mHandler.handle\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    977\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 978\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    980\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\logging\\__init__.py:1118\u001b[0m, in \u001b[0;36mStreamHandler.emit\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m   1116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m   1117\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m-> 1118\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandleError\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\logging\\__init__.py:1031\u001b[0m, in \u001b[0;36mHandler.handleError\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m   1029\u001b[0m t, v, tb \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n\u001b[0;32m   1030\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1031\u001b[0m     \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--- Logging error ---\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1032\u001b[0m     traceback\u001b[38;5;241m.\u001b[39mprint_exception(t, v, tb, \u001b[38;5;28;01mNone\u001b[39;00m, sys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m   1033\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCall stack:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\After\\Fuse AI Trainee\\fuse_env\\Lib\\site-packages\\colorama\\ansitowin32.py:41\u001b[0m, in \u001b[0;36mStreamWrapper.write\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__convertor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\After\\Fuse AI Trainee\\fuse_env\\Lib\\site-packages\\colorama\\ansitowin32.py:164\u001b[0m, in \u001b[0;36mAnsiToWin32.write\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_and_convert(text)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapped\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautoreset:\n",
      "File \u001b[1;32md:\\After\\Fuse AI Trainee\\fuse_env\\Lib\\site-packages\\colorama\\ansitowin32.py:41\u001b[0m, in \u001b[0;36mStreamWrapper.write\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__convertor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\After\\Fuse AI Trainee\\fuse_env\\Lib\\site-packages\\colorama\\ansitowin32.py:162\u001b[0m, in \u001b[0;36mAnsiToWin32.write\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrip \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert:\n\u001b[1;32m--> 162\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_and_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapped\u001b[38;5;241m.\u001b[39mwrite(text)\n",
      "File \u001b[1;32md:\\After\\Fuse AI Trainee\\fuse_env\\Lib\\site-packages\\colorama\\ansitowin32.py:190\u001b[0m, in \u001b[0;36mAnsiToWin32.write_and_convert\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_ansi(\u001b[38;5;241m*\u001b[39mmatch\u001b[38;5;241m.\u001b[39mgroups())\n\u001b[0;32m    189\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m end\n\u001b[1;32m--> 190\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_plain_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\After\\Fuse AI Trainee\\fuse_env\\Lib\\site-packages\\colorama\\ansitowin32.py:195\u001b[0m, in \u001b[0;36mAnsiToWin32.write_plain_text\u001b[1;34m(self, text, start, end)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite_plain_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, start, end):\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;241m<\u001b[39m end:\n\u001b[1;32m--> 195\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapped\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[1;32md:\\After\\Fuse AI Trainee\\fuse_env\\Lib\\site-packages\\colorama\\ansitowin32.py:41\u001b[0m, in \u001b[0;36mStreamWrapper.write\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__convertor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\After\\Fuse AI Trainee\\fuse_env\\Lib\\site-packages\\colorama\\ansitowin32.py:162\u001b[0m, in \u001b[0;36mAnsiToWin32.write\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrip \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert:\n\u001b[1;32m--> 162\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_and_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapped\u001b[38;5;241m.\u001b[39mwrite(text)\n",
      "File \u001b[1;32md:\\After\\Fuse AI Trainee\\fuse_env\\Lib\\site-packages\\colorama\\ansitowin32.py:190\u001b[0m, in \u001b[0;36mAnsiToWin32.write_and_convert\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_ansi(\u001b[38;5;241m*\u001b[39mmatch\u001b[38;5;241m.\u001b[39mgroups())\n\u001b[0;32m    189\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m end\n\u001b[1;32m--> 190\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_plain_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\After\\Fuse AI Trainee\\fuse_env\\Lib\\site-packages\\colorama\\ansitowin32.py:195\u001b[0m, in \u001b[0;36mAnsiToWin32.write_plain_text\u001b[1;34m(self, text, start, end)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite_plain_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, start, end):\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;241m<\u001b[39m end:\n\u001b[1;32m--> 195\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapped\u001b[38;5;241m.\u001b[39mflush()\n",
      "    \u001b[1;31m[... skipping similar frames: StreamWrapper.write at line 41 (4 times), AnsiToWin32.write at line 162 (4 times), AnsiToWin32.write_and_convert at line 190 (4 times), AnsiToWin32.write_plain_text at line 195 (4 times)]\u001b[0m\n",
      "File \u001b[1;32md:\\After\\Fuse AI Trainee\\fuse_env\\Lib\\site-packages\\colorama\\ansitowin32.py:41\u001b[0m, in \u001b[0;36mStreamWrapper.write\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__convertor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\After\\Fuse AI Trainee\\fuse_env\\Lib\\site-packages\\colorama\\ansitowin32.py:162\u001b[0m, in \u001b[0;36mAnsiToWin32.write\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrip \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert:\n\u001b[1;32m--> 162\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_and_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapped\u001b[38;5;241m.\u001b[39mwrite(text)\n",
      "File \u001b[1;32md:\\After\\Fuse AI Trainee\\fuse_env\\Lib\\site-packages\\colorama\\ansitowin32.py:190\u001b[0m, in \u001b[0;36mAnsiToWin32.write_and_convert\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_ansi(\u001b[38;5;241m*\u001b[39mmatch\u001b[38;5;241m.\u001b[39mgroups())\n\u001b[0;32m    189\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m end\n\u001b[1;32m--> 190\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_plain_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\After\\Fuse AI Trainee\\fuse_env\\Lib\\site-packages\\colorama\\ansitowin32.py:195\u001b[0m, in \u001b[0;36mAnsiToWin32.write_plain_text\u001b[1;34m(self, text, start, end)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite_plain_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, start, end):\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m start \u001b[38;5;241m<\u001b[39m end:\n\u001b[1;32m--> 195\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrapped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapped\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[1;32md:\\After\\Fuse AI Trainee\\fuse_env\\Lib\\site-packages\\ipykernel\\iostream.py:679\u001b[0m, in \u001b[0;36mOutStream.write\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    678\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI/O operation on closed file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 679\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    681\u001b[0m is_child \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_master_process()\n\u001b[0;32m    682\u001b[0m \u001b[38;5;66;03m# only touch the buffer in the IO thread to avoid races\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from recbole.quick_start import load_data_and_model\n",
    "\n",
    "# Load the trained model and data\n",
    "config, model, dataset, train_data, valid_data, test_data = load_data_and_model(model_file='saved\\\\NFM-Jun-21-2024_15-18-19.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_next_item_recommendations(user_id, seq_len=5, top_k=5):\n",
    "    # Get the user's interaction sequence\n",
    "    user_interactions = train_data.dataset.inter_feat[train_data.dataset.inter_feat['user_id'] == user_id]\n",
    "    user_interactions = user_interactions['item_id'].tolist()\n",
    "    \n",
    "    if len(user_interactions) < seq_len:\n",
    "        seq = [0] * (seq_len - len(user_interactions)) + user_interactions\n",
    "    else:\n",
    "        seq = user_interactions[-seq_len:]\n",
    "    \n",
    "    seq = torch.tensor(seq).unsqueeze(0).to(config['device'])\n",
    "    \n",
    "    # Get top-k next item recommendations\n",
    "    scores = model.full_sort_predict(seq)\n",
    "    topk_items = scores.topk(top_k).indices.squeeze().cpu().numpy()\n",
    "    \n",
    "    return topk_items\n",
    "\n",
    "def print_joke(joke_id):\n",
    "    # Print joke text given a joke ID\n",
    "    joke_text = jokes_df[jokes_df['jokeId'] == joke_id]['jokeText'].values[0]\n",
    "    print(joke_text)\n",
    "\n",
    "# Interactive recommendation loop\n",
    "import random\n",
    "\n",
    "user_id = random.choice(ratings_df['user_id'].unique())\n",
    "while True:\n",
    "    recommended_jokes = get_next_item_recommendations(user_id)\n",
    "    \n",
    "    print(\"Recommended Jokes:\")\n",
    "    for i, joke_id in enumerate(recommended_jokes, 1):\n",
    "        print(f\"{i}. Joke ID {joke_id}\")\n",
    "    \n",
    "    choice = input(\"Enter the number of the joke you like (or 'exit' to stop): \")\n",
    "    \n",
    "    if choice.lower() == 'exit':\n",
    "        break\n",
    "    \n",
    "    try:\n",
    "        selected_index = int(choice) - 1\n",
    "        selected_joke_id = recommended_jokes[selected_index]\n",
    "        \n",
    "        print(\"\\nSelected Joke:\")\n",
    "        print_joke(selected_joke_id)\n",
    "        \n",
    "        # Update recommendations based on the chosen joke\n",
    "        recommended_jokes = get_next_item_recommendations(user_id, seq_len=5, top_k=5)\n",
    "    except (ValueError, IndexError):\n",
    "        print(\"Invalid choice. Please try again.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fuse_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
